{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys_version 3.5.2 (default, Nov 17 2016, 17:05:23) [GCC 5.4.0 20160609]\n",
      "virtual_env None\n",
      "pwd /home/marko/Projects/faks/NN_face_recognition/nn_devel\n",
      "np  1.11.1\n",
      "tf  0.10.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import facenet\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pdb\n",
    "import time\n",
    "import cv2\n",
    "from preprocess.image_preprocess import get_faces_from_img\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('sys_version', sys.version.replace('\\n', ''))\n",
    "print('virtual_env', os.environ.get('VIRTUAL_ENV', 'None'))\n",
    "print('pwd', os.getcwd())\n",
    "print('np ', np.__version__)\n",
    "print('tf ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# args\n",
    "model_dir = './saved_models/model-20160506/'\n",
    "meta_file = 'model.ckpt-500000.meta'\n",
    "ckpt_file = 'model.ckpt-500000'\n",
    "\n",
    "log_dir = './log/'\n",
    "img_dim = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metagraph file: model.ckpt-500000.meta\n",
      "Checkpoint file: model.ckpt-500000\n",
      "Total number of parameters: 6959088\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess =  tf.Session()\n",
    "with sess.as_default():\n",
    "    summary_writer = tf.train.SummaryWriter('./log/',graph_def=sess.graph_def)\n",
    "    print('Metagraph file: %s' % meta_file)\n",
    "    print('Checkpoint file: %s' % ckpt_file)\n",
    "    facenet.load_model(model_dir, meta_file, ckpt_file)\n",
    "    \n",
    "writer = tf.train.SummaryWriter(log_dir, graph=tf.get_default_graph())\n",
    "\n",
    "def total_params():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        shape = variable.get_shape()\n",
    "        variable_parametes = 1\n",
    "        for dim in shape:\n",
    "            variable_parametes *= dim.value\n",
    "        total_parameters += variable_parametes\n",
    "    return total_parameters\n",
    "    \n",
    "print(\"Total number of parameters:\", total_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get input and output tensors\n",
    "images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "\n",
    "image_size = images_placeholder.get_shape()[1]\n",
    "embeddings_size = embeddings.get_shape()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_7x7_1/weights:0 (7, 7, 3, 64)\n",
      "conv1_7x7_1/batch_norm/batch_norm/beta:0 (64,)\n",
      "conv1_7x7_1/batch_norm/batch_norm/gamma:0 (64,)\n",
      "conv1_7x7_1/biases:0 (64,)\n",
      "conv2_1x1_2/weights:0 (1, 1, 64, 64)\n",
      "conv2_1x1_2/batch_norm/batch_norm/beta:0 (64,)\n",
      "conv2_1x1_2/batch_norm/batch_norm/gamma:0 (64,)\n",
      "conv2_1x1_2/biases:0 (64,)\n",
      "conv3_3x3_3/weights:0 (3, 3, 64, 192)\n",
      "conv3_3x3_3/batch_norm/batch_norm/beta:0 (192,)\n",
      "conv3_3x3_3/batch_norm/batch_norm/gamma:0 (192,)\n",
      "conv3_3x3_3/biases:0 (192,)\n",
      "incept3a/in1_conv1x1_4/weights:0 (1, 1, 192, 64)\n",
      "incept3a/in1_conv1x1_4/batch_norm/batch_norm/beta:0 (64,)\n",
      "incept3a/in1_conv1x1_4/batch_norm/batch_norm/gamma:0 (64,)\n",
      "incept3a/in1_conv1x1_4/biases:0 (64,)\n",
      "incept3a/in2_conv1x1_5/weights:0 (1, 1, 192, 96)\n",
      "incept3a/in2_conv1x1_5/batch_norm/batch_norm/beta:0 (96,)\n",
      "incept3a/in2_conv1x1_5/batch_norm/batch_norm/gamma:0 (96,)\n",
      "incept3a/in2_conv1x1_5/biases:0 (96,)\n",
      "incept3a/in2_conv3x3_6/weights:0 (3, 3, 96, 128)\n",
      "incept3a/in2_conv3x3_6/batch_norm/batch_norm/beta:0 (128,)\n",
      "incept3a/in2_conv3x3_6/batch_norm/batch_norm/gamma:0 (128,)\n",
      "incept3a/in2_conv3x3_6/biases:0 (128,)\n",
      "incept3a/in3_conv1x1_7/weights:0 (1, 1, 192, 16)\n",
      "incept3a/in3_conv1x1_7/batch_norm/batch_norm/beta:0 (16,)\n",
      "incept3a/in3_conv1x1_7/batch_norm/batch_norm/gamma:0 (16,)\n",
      "incept3a/in3_conv1x1_7/biases:0 (16,)\n",
      "incept3a/in3_conv5x5_8/weights:0 (5, 5, 16, 32)\n",
      "incept3a/in3_conv5x5_8/batch_norm/batch_norm/beta:0 (32,)\n",
      "incept3a/in3_conv5x5_8/batch_norm/batch_norm/gamma:0 (32,)\n",
      "incept3a/in3_conv5x5_8/biases:0 (32,)\n",
      "incept3a/in4_conv1x1_9/weights:0 (1, 1, 192, 32)\n",
      "incept3a/in4_conv1x1_9/batch_norm/batch_norm/beta:0 (32,)\n",
      "incept3a/in4_conv1x1_9/batch_norm/batch_norm/gamma:0 (32,)\n",
      "incept3a/in4_conv1x1_9/biases:0 (32,)\n",
      "incept3b/in1_conv1x1_10/weights:0 (1, 1, 256, 64)\n",
      "incept3b/in1_conv1x1_10/batch_norm/batch_norm/beta:0 (64,)\n",
      "incept3b/in1_conv1x1_10/batch_norm/batch_norm/gamma:0 (64,)\n",
      "incept3b/in1_conv1x1_10/biases:0 (64,)\n",
      "incept3b/in2_conv1x1_11/weights:0 (1, 1, 256, 96)\n",
      "incept3b/in2_conv1x1_11/batch_norm/batch_norm/beta:0 (96,)\n",
      "incept3b/in2_conv1x1_11/batch_norm/batch_norm/gamma:0 (96,)\n",
      "incept3b/in2_conv1x1_11/biases:0 (96,)\n",
      "incept3b/in2_conv3x3_12/weights:0 (3, 3, 96, 128)\n",
      "incept3b/in2_conv3x3_12/batch_norm/batch_norm/beta:0 (128,)\n",
      "incept3b/in2_conv3x3_12/batch_norm/batch_norm/gamma:0 (128,)\n",
      "incept3b/in2_conv3x3_12/biases:0 (128,)\n",
      "incept3b/in3_conv1x1_13/weights:0 (1, 1, 256, 32)\n",
      "incept3b/in3_conv1x1_13/batch_norm/batch_norm/beta:0 (32,)\n",
      "incept3b/in3_conv1x1_13/batch_norm/batch_norm/gamma:0 (32,)\n",
      "incept3b/in3_conv1x1_13/biases:0 (32,)\n",
      "incept3b/in3_conv5x5_14/weights:0 (5, 5, 32, 64)\n",
      "incept3b/in3_conv5x5_14/batch_norm/batch_norm/beta:0 (64,)\n",
      "incept3b/in3_conv5x5_14/batch_norm/batch_norm/gamma:0 (64,)\n",
      "incept3b/in3_conv5x5_14/biases:0 (64,)\n",
      "incept3b/in4_conv1x1_15/weights:0 (1, 1, 256, 64)\n",
      "incept3b/in4_conv1x1_15/batch_norm/batch_norm/beta:0 (64,)\n",
      "incept3b/in4_conv1x1_15/batch_norm/batch_norm/gamma:0 (64,)\n",
      "incept3b/in4_conv1x1_15/biases:0 (64,)\n",
      "incept3c/in2_conv1x1_16/weights:0 (1, 1, 320, 128)\n",
      "incept3c/in2_conv1x1_16/batch_norm/batch_norm/beta:0 (128,)\n",
      "incept3c/in2_conv1x1_16/batch_norm/batch_norm/gamma:0 (128,)\n",
      "incept3c/in2_conv1x1_16/biases:0 (128,)\n",
      "incept3c/in2_conv3x3_17/weights:0 (3, 3, 128, 256)\n",
      "incept3c/in2_conv3x3_17/batch_norm/batch_norm/beta:0 (256,)\n",
      "incept3c/in2_conv3x3_17/batch_norm/batch_norm/gamma:0 (256,)\n",
      "incept3c/in2_conv3x3_17/biases:0 (256,)\n",
      "incept3c/in3_conv1x1_18/weights:0 (1, 1, 320, 32)\n",
      "incept3c/in3_conv1x1_18/batch_norm/batch_norm/beta:0 (32,)\n",
      "incept3c/in3_conv1x1_18/batch_norm/batch_norm/gamma:0 (32,)\n",
      "incept3c/in3_conv1x1_18/biases:0 (32,)\n",
      "incept3c/in3_conv5x5_19/weights:0 (5, 5, 32, 64)\n",
      "incept3c/in3_conv5x5_19/batch_norm/batch_norm/beta:0 (64,)\n",
      "incept3c/in3_conv5x5_19/batch_norm/batch_norm/gamma:0 (64,)\n",
      "incept3c/in3_conv5x5_19/biases:0 (64,)\n",
      "incept4a/in1_conv1x1_20/weights:0 (1, 1, 640, 256)\n",
      "incept4a/in1_conv1x1_20/batch_norm/batch_norm/beta:0 (256,)\n",
      "incept4a/in1_conv1x1_20/batch_norm/batch_norm/gamma:0 (256,)\n",
      "incept4a/in1_conv1x1_20/biases:0 (256,)\n",
      "incept4a/in2_conv1x1_21/weights:0 (1, 1, 640, 96)\n",
      "incept4a/in2_conv1x1_21/batch_norm/batch_norm/beta:0 (96,)\n",
      "incept4a/in2_conv1x1_21/batch_norm/batch_norm/gamma:0 (96,)\n",
      "incept4a/in2_conv1x1_21/biases:0 (96,)\n",
      "incept4a/in2_conv3x3_22/weights:0 (3, 3, 96, 192)\n",
      "incept4a/in2_conv3x3_22/batch_norm/batch_norm/beta:0 (192,)\n",
      "incept4a/in2_conv3x3_22/batch_norm/batch_norm/gamma:0 (192,)\n",
      "incept4a/in2_conv3x3_22/biases:0 (192,)\n",
      "incept4a/in3_conv1x1_23/weights:0 (1, 1, 640, 32)\n",
      "incept4a/in3_conv1x1_23/batch_norm/batch_norm/beta:0 (32,)\n",
      "incept4a/in3_conv1x1_23/batch_norm/batch_norm/gamma:0 (32,)\n",
      "incept4a/in3_conv1x1_23/biases:0 (32,)\n",
      "incept4a/in3_conv5x5_24/weights:0 (5, 5, 32, 64)\n",
      "incept4a/in3_conv5x5_24/batch_norm/batch_norm/beta:0 (64,)\n",
      "incept4a/in3_conv5x5_24/batch_norm/batch_norm/gamma:0 (64,)\n",
      "incept4a/in3_conv5x5_24/biases:0 (64,)\n",
      "incept4a/in4_conv1x1_25/weights:0 (1, 1, 640, 128)\n",
      "incept4a/in4_conv1x1_25/batch_norm/batch_norm/beta:0 (128,)\n",
      "incept4a/in4_conv1x1_25/batch_norm/batch_norm/gamma:0 (128,)\n",
      "incept4a/in4_conv1x1_25/biases:0 (128,)\n",
      "incept4b/in1_conv1x1_26/weights:0 (1, 1, 640, 224)\n",
      "incept4b/in1_conv1x1_26/batch_norm/batch_norm/beta:0 (224,)\n",
      "incept4b/in1_conv1x1_26/batch_norm/batch_norm/gamma:0 (224,)\n",
      "incept4b/in1_conv1x1_26/biases:0 (224,)\n",
      "incept4b/in2_conv1x1_27/weights:0 (1, 1, 640, 112)\n",
      "incept4b/in2_conv1x1_27/batch_norm/batch_norm/beta:0 (112,)\n",
      "incept4b/in2_conv1x1_27/batch_norm/batch_norm/gamma:0 (112,)\n",
      "incept4b/in2_conv1x1_27/biases:0 (112,)\n",
      "incept4b/in2_conv3x3_28/weights:0 (3, 3, 112, 224)\n",
      "incept4b/in2_conv3x3_28/batch_norm/batch_norm/beta:0 (224,)\n",
      "incept4b/in2_conv3x3_28/batch_norm/batch_norm/gamma:0 (224,)\n",
      "incept4b/in2_conv3x3_28/biases:0 (224,)\n",
      "incept4b/in3_conv1x1_29/weights:0 (1, 1, 640, 32)\n",
      "incept4b/in3_conv1x1_29/batch_norm/batch_norm/beta:0 (32,)\n",
      "incept4b/in3_conv1x1_29/batch_norm/batch_norm/gamma:0 (32,)\n",
      "incept4b/in3_conv1x1_29/biases:0 (32,)\n",
      "incept4b/in3_conv5x5_30/weights:0 (5, 5, 32, 64)\n",
      "incept4b/in3_conv5x5_30/batch_norm/batch_norm/beta:0 (64,)\n",
      "incept4b/in3_conv5x5_30/batch_norm/batch_norm/gamma:0 (64,)\n",
      "incept4b/in3_conv5x5_30/biases:0 (64,)\n",
      "incept4b/in4_conv1x1_31/weights:0 (1, 1, 640, 128)\n",
      "incept4b/in4_conv1x1_31/batch_norm/batch_norm/beta:0 (128,)\n",
      "incept4b/in4_conv1x1_31/batch_norm/batch_norm/gamma:0 (128,)\n",
      "incept4b/in4_conv1x1_31/biases:0 (128,)\n",
      "incept4c/in1_conv1x1_32/weights:0 (1, 1, 640, 192)\n",
      "incept4c/in1_conv1x1_32/batch_norm/batch_norm/beta:0 (192,)\n",
      "incept4c/in1_conv1x1_32/batch_norm/batch_norm/gamma:0 (192,)\n",
      "incept4c/in1_conv1x1_32/biases:0 (192,)\n",
      "incept4c/in2_conv1x1_33/weights:0 (1, 1, 640, 128)\n",
      "incept4c/in2_conv1x1_33/batch_norm/batch_norm/beta:0 (128,)\n",
      "incept4c/in2_conv1x1_33/batch_norm/batch_norm/gamma:0 (128,)\n",
      "incept4c/in2_conv1x1_33/biases:0 (128,)\n",
      "incept4c/in2_conv3x3_34/weights:0 (3, 3, 128, 256)\n",
      "incept4c/in2_conv3x3_34/batch_norm/batch_norm/beta:0 (256,)\n",
      "incept4c/in2_conv3x3_34/batch_norm/batch_norm/gamma:0 (256,)\n",
      "incept4c/in2_conv3x3_34/biases:0 (256,)\n",
      "incept4c/in3_conv1x1_35/weights:0 (1, 1, 640, 32)\n",
      "incept4c/in3_conv1x1_35/batch_norm/batch_norm/beta:0 (32,)\n",
      "incept4c/in3_conv1x1_35/batch_norm/batch_norm/gamma:0 (32,)\n",
      "incept4c/in3_conv1x1_35/biases:0 (32,)\n",
      "incept4c/in3_conv5x5_36/weights:0 (5, 5, 32, 64)\n",
      "incept4c/in3_conv5x5_36/batch_norm/batch_norm/beta:0 (64,)\n",
      "incept4c/in3_conv5x5_36/batch_norm/batch_norm/gamma:0 (64,)\n",
      "incept4c/in3_conv5x5_36/biases:0 (64,)\n",
      "incept4c/in4_conv1x1_37/weights:0 (1, 1, 640, 128)\n",
      "incept4c/in4_conv1x1_37/batch_norm/batch_norm/beta:0 (128,)\n",
      "incept4c/in4_conv1x1_37/batch_norm/batch_norm/gamma:0 (128,)\n",
      "incept4c/in4_conv1x1_37/biases:0 (128,)\n",
      "incept4d/in1_conv1x1_38/weights:0 (1, 1, 640, 160)\n",
      "incept4d/in1_conv1x1_38/batch_norm/batch_norm/beta:0 (160,)\n",
      "incept4d/in1_conv1x1_38/batch_norm/batch_norm/gamma:0 (160,)\n",
      "incept4d/in1_conv1x1_38/biases:0 (160,)\n",
      "incept4d/in2_conv1x1_39/weights:0 (1, 1, 640, 144)\n",
      "incept4d/in2_conv1x1_39/batch_norm/batch_norm/beta:0 (144,)\n",
      "incept4d/in2_conv1x1_39/batch_norm/batch_norm/gamma:0 (144,)\n",
      "incept4d/in2_conv1x1_39/biases:0 (144,)\n",
      "incept4d/in2_conv3x3_40/weights:0 (3, 3, 144, 288)\n",
      "incept4d/in2_conv3x3_40/batch_norm/batch_norm/beta:0 (288,)\n",
      "incept4d/in2_conv3x3_40/batch_norm/batch_norm/gamma:0 (288,)\n",
      "incept4d/in2_conv3x3_40/biases:0 (288,)\n",
      "incept4d/in3_conv1x1_41/weights:0 (1, 1, 640, 32)\n",
      "incept4d/in3_conv1x1_41/batch_norm/batch_norm/beta:0 (32,)\n",
      "incept4d/in3_conv1x1_41/batch_norm/batch_norm/gamma:0 (32,)\n",
      "incept4d/in3_conv1x1_41/biases:0 (32,)\n",
      "incept4d/in3_conv5x5_42/weights:0 (5, 5, 32, 64)\n",
      "incept4d/in3_conv5x5_42/batch_norm/batch_norm/beta:0 (64,)\n",
      "incept4d/in3_conv5x5_42/batch_norm/batch_norm/gamma:0 (64,)\n",
      "incept4d/in3_conv5x5_42/biases:0 (64,)\n",
      "incept4d/in4_conv1x1_43/weights:0 (1, 1, 640, 128)\n",
      "incept4d/in4_conv1x1_43/batch_norm/batch_norm/beta:0 (128,)\n",
      "incept4d/in4_conv1x1_43/batch_norm/batch_norm/gamma:0 (128,)\n",
      "incept4d/in4_conv1x1_43/biases:0 (128,)\n",
      "incept4e/in2_conv1x1_44/weights:0 (1, 1, 640, 160)\n",
      "incept4e/in2_conv1x1_44/batch_norm/batch_norm/beta:0 (160,)\n",
      "incept4e/in2_conv1x1_44/batch_norm/batch_norm/gamma:0 (160,)\n",
      "incept4e/in2_conv1x1_44/biases:0 (160,)\n",
      "incept4e/in2_conv3x3_45/weights:0 (3, 3, 160, 256)\n",
      "incept4e/in2_conv3x3_45/batch_norm/batch_norm/beta:0 (256,)\n",
      "incept4e/in2_conv3x3_45/batch_norm/batch_norm/gamma:0 (256,)\n",
      "incept4e/in2_conv3x3_45/biases:0 (256,)\n",
      "incept4e/in3_conv1x1_46/weights:0 (1, 1, 640, 64)\n",
      "incept4e/in3_conv1x1_46/batch_norm/batch_norm/beta:0 (64,)\n",
      "incept4e/in3_conv1x1_46/batch_norm/batch_norm/gamma:0 (64,)\n",
      "incept4e/in3_conv1x1_46/biases:0 (64,)\n",
      "incept4e/in3_conv5x5_47/weights:0 (5, 5, 64, 128)\n",
      "incept4e/in3_conv5x5_47/batch_norm/batch_norm/beta:0 (128,)\n",
      "incept4e/in3_conv5x5_47/batch_norm/batch_norm/gamma:0 (128,)\n",
      "incept4e/in3_conv5x5_47/biases:0 (128,)\n",
      "incept5a/in1_conv1x1_48/weights:0 (1, 1, 1024, 384)\n",
      "incept5a/in1_conv1x1_48/batch_norm/batch_norm/beta:0 (384,)\n",
      "incept5a/in1_conv1x1_48/batch_norm/batch_norm/gamma:0 (384,)\n",
      "incept5a/in1_conv1x1_48/biases:0 (384,)\n",
      "incept5a/in2_conv1x1_49/weights:0 (1, 1, 1024, 192)\n",
      "incept5a/in2_conv1x1_49/batch_norm/batch_norm/beta:0 (192,)\n",
      "incept5a/in2_conv1x1_49/batch_norm/batch_norm/gamma:0 (192,)\n",
      "incept5a/in2_conv1x1_49/biases:0 (192,)\n",
      "incept5a/in2_conv3x3_50/weights:0 (3, 3, 192, 384)\n",
      "incept5a/in2_conv3x3_50/batch_norm/batch_norm/beta:0 (384,)\n",
      "incept5a/in2_conv3x3_50/batch_norm/batch_norm/gamma:0 (384,)\n",
      "incept5a/in2_conv3x3_50/biases:0 (384,)\n",
      "incept5a/in4_conv1x1_51/weights:0 (1, 1, 1024, 128)\n",
      "incept5a/in4_conv1x1_51/batch_norm/batch_norm/beta:0 (128,)\n",
      "incept5a/in4_conv1x1_51/batch_norm/batch_norm/gamma:0 (128,)\n",
      "incept5a/in4_conv1x1_51/biases:0 (128,)\n",
      "incept5b/in1_conv1x1_52/weights:0 (1, 1, 896, 384)\n",
      "incept5b/in1_conv1x1_52/batch_norm/batch_norm/beta:0 (384,)\n",
      "incept5b/in1_conv1x1_52/batch_norm/batch_norm/gamma:0 (384,)\n",
      "incept5b/in1_conv1x1_52/biases:0 (384,)\n",
      "incept5b/in2_conv1x1_53/weights:0 (1, 1, 896, 192)\n",
      "incept5b/in2_conv1x1_53/batch_norm/batch_norm/beta:0 (192,)\n",
      "incept5b/in2_conv1x1_53/batch_norm/batch_norm/gamma:0 (192,)\n",
      "incept5b/in2_conv1x1_53/biases:0 (192,)\n",
      "incept5b/in2_conv3x3_54/weights:0 (3, 3, 192, 384)\n",
      "incept5b/in2_conv3x3_54/batch_norm/batch_norm/beta:0 (384,)\n",
      "incept5b/in2_conv3x3_54/batch_norm/batch_norm/gamma:0 (384,)\n",
      "incept5b/in2_conv3x3_54/biases:0 (384,)\n",
      "incept5b/in4_conv1x1_55/weights:0 (1, 1, 896, 128)\n",
      "incept5b/in4_conv1x1_55/batch_norm/batch_norm/beta:0 (128,)\n",
      "incept5b/in4_conv1x1_55/batch_norm/batch_norm/gamma:0 (128,)\n",
      "incept5b/in4_conv1x1_55/biases:0 (128,)\n",
      "affine1/weights:0 (896, 128)\n",
      "affine1/biases:0 (128,)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    shape = variable.get_shape()\n",
    "    print(variable.name, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFW evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(embeddings, seed, actual_issame, nrof_folds=10):\n",
    "    # Calculate evaluation metrics\n",
    "    thresholds = np.arange(0, 4, 0.01)\n",
    "    embeddings1 = embeddings[0::2]\n",
    "    embeddings2 = embeddings[1::2]\n",
    "    tpr, fpr, accuracy = facenet.calculate_roc(thresholds, embeddings1, embeddings2,\n",
    "        np.asarray(actual_issame), seed, nrof_folds=nrof_folds)\n",
    "    thresholds = np.arange(0, 4, 0.001)\n",
    "    val, val_std, far = facenet.calculate_val(thresholds, embeddings1, embeddings2,\n",
    "        np.asarray(actual_issame), 1e-3, seed, nrof_folds=nrof_folds)\n",
    "    return tpr, fpr, accuracy, val, val_std, far\n",
    "\n",
    "def read_pairs(pairs_filename):\n",
    "    \"\"\" Read pairs.txt file \"\"\"\n",
    "    pairs = []\n",
    "    with open(pairs_filename, 'r') as f:\n",
    "        for line in f.readlines()[1:]:\n",
    "            pair = line.strip().split()\n",
    "            pairs.append(pair)\n",
    "    return np.array(pairs)\n",
    "\n",
    "def get_paths(lfw_dir, pairs, file_ext):\n",
    "    \"\"\" Gets path of aligned lfw images\"\"\"\n",
    "    nrof_skipped_pairs = 0\n",
    "    path_list = []\n",
    "    issame_list = []\n",
    "    \n",
    "    def file_name(name, cnt):\n",
    "        return \"%s_%04d_0.%s\" % (name, int(cnt), file_ext)\n",
    "\n",
    "    for pair in pairs:\n",
    "        if len(pair) == 3:\n",
    "            \n",
    "            path0 = os.path.join(lfw_dir, pair[0], file_name(pair[0], pair[1]))\n",
    "            path1 = os.path.join(lfw_dir, pair[0], file_name(pair[0], pair[2]))\n",
    "            issame = True\n",
    "        elif len(pair) == 4:\n",
    "            path0 = os.path.join(lfw_dir, pair[0], file_name(pair[0], pair[1]))\n",
    "            path1 = os.path.join(lfw_dir, pair[2], file_name(pair[2], pair[3]))\n",
    "            issame = False\n",
    "\n",
    "            \n",
    "        if os.path.exists(path0) and os.path.exists(path1):    # Only add the pair if both paths exist\n",
    "            path_list += (path0,path1)\n",
    "            issame_list.append(issame)\n",
    "        else:\n",
    "            nrof_skipped_pairs += 1\n",
    "    if nrof_skipped_pairs>0:\n",
    "        print('Skipped %d image pairs' % nrof_skipped_pairs)\n",
    "    \n",
    "    return path_list, issame_list\n",
    "\n",
    "def calc_auc(fprs, tprs):\n",
    "    \"\"\" From openface \"\"\"\n",
    "    sortedFprs, sortedTprs = zip(*sorted(zip(*(fprs, tprs))))\n",
    "    sortedFprs = list(sortedFprs)\n",
    "    sortedTprs = list(sortedTprs)\n",
    "    if sortedFprs[-1] != 1.0:\n",
    "        sortedFprs.append(1.0)\n",
    "        sortedTprs.append(sortedTprs[-1])\n",
    "    return np.trapz(sortedTprs, sortedFprs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 46 image pairs\n"
     ]
    }
   ],
   "source": [
    "lfw_pairs = './data/pairs.txt'\n",
    "lfw_dir = './data/aligned_lfw/'\n",
    "lfw_file_ext = 'png'\n",
    "batch_size = 100\n",
    "n_folds = 10\n",
    "random_seed= 42\n",
    "\n",
    "\n",
    "pairs = read_pairs(os.path.expanduser(lfw_pairs))\n",
    "paths, actual_issame = get_paths(os.path.expanduser(lfw_dir), pairs, lfw_file_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_images = len(paths)\n",
    "n_batches = int(math.ceil(n_images / batch_size))\n",
    "embeddings_array = np.zeros((n_images, embeddings_size))\n",
    "\n",
    "\n",
    "for i in range(n_batches):\n",
    "    print(\"Batch %s/%s;\" % (i, n_batches), end='')\n",
    "    s_time = time.time()\n",
    "    start_index = i*batch_size\n",
    "    end_index = min((i+1)*batch_size, n_images)\n",
    "    \n",
    "    paths_batch = paths[start_index:end_index]\n",
    "    \n",
    "    images = facenet.load_data(paths_batch, image_size)\n",
    "    feed_dict = { images_placeholder:images, phase_train_placeholder:False  }\n",
    "    embeddings_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "    print(\"duration: \", time.time() - s_time)\n",
    "\n",
    "tpr, fpr, accuracy, val, val_std, far = evaluate(embeddings_array, random_seed, actual_issame, nrof_folds=n_folds)\n",
    "auc = calc_auc(fpr, tpr)\n",
    "\n",
    "\n",
    "print('Accuracy: %1.3f+-%1.3f' % (np.mean(accuracy), np.std(accuracy)))\n",
    "print('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))\n",
    "print('AUC: %1.3f' % auc)\n",
    "facenet.plot_roc(fpr, tpr, 'tf_nn4 [AUC = %1.3f]' % auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Camera Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "## Record samples\n",
    "\n",
    "sample photos for person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/samples/Marko\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/home/marko/local/opencv/modules/highgui/src/window.cpp:281: error: (-215) size.width>0 && size.height>0 in function imshow\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b3b66afbc7b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /home/marko/local/opencv/modules/highgui/src/window.cpp:281: error: (-215) size.width>0 && size.height>0 in function imshow\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def init_dir(d):\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "person_name = 'Marko'\n",
    "output_root = 'data/samples/'\n",
    "\n",
    "out_dir = os.path.join(output_root, person_name)\n",
    "init_dir(out_dir)\n",
    "print(out_dir)\n",
    "n = 500\n",
    "skip = 10\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    i += 1\n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "    key = cv2.waitKey(1) & 0xff\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if i % skip != 0: continue\n",
    "\n",
    "    s = cv2.imwrite(os.path.join(out_dir, '%07d.png' % (i/skip)), frame)\n",
    "    print(i/skip, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7077a9818e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os.path import join, basename\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name, root_dir):\n",
    "        self.name = name\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "    def load_paths(self, formats=['.png']):\n",
    "        self.paths = []\n",
    "        for ext in formats:\n",
    "            self.paths += glob(join(self.root_dir, '*' + ext))\n",
    "        \n",
    "        \n",
    "    def load_imgs(self, img_size=96, formats=['.png']):\n",
    "        self.load_paths(formats)\n",
    "        \n",
    "        self.imgs = []\n",
    "        for path in self.paths:\n",
    "            img = facenet.load_data([path], img_size)[0]\n",
    "            self.imgs.append(img)\n",
    "            \n",
    "        self.imgs = np.array(self.imgs)\n",
    "\n",
    "\n",
    "def load_imgs(paths):\n",
    "    return facenet.load_data(paths, image_size=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4598 4598\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "from glob import glob\n",
    "\n",
    "def get_embeddings(imgs):\n",
    "    feed_dict = { images_placeholder:imgs, phase_train_placeholder:False  }\n",
    "    return sess.run(embeddings, feed_dict=feed_dict)\n",
    "\n",
    "root = './data/aligned_lfw/'\n",
    "names = os.listdir(root)\n",
    "\n",
    "people = [Person(d, join(root, d)) for d in names]\n",
    "selected = []\n",
    "for p in people: \n",
    "    p.load_paths()\n",
    "    if len(p.paths) > 10:\n",
    "        p.load_imgs()\n",
    "        selected.append(p)\n",
    "    \n",
    "    \n",
    "    \n",
    "def create_samples(people):\n",
    "    Xs = []; ys = []; to_names = dict()\n",
    "    \n",
    "    for i, p in enumerate(people):\n",
    "        Xs += get_embeddings(p.imgs).tolist()\n",
    "        ys += [i] * len(p.imgs)\n",
    "        to_names[i] = p.name\n",
    "        \n",
    "    return np.vstack(Xs), np.vstack(ys), to_names\n",
    "\n",
    "Xs, ys, to_names = create_samples(selected)\n",
    "print(len(Xs), len(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'James_Blake')\n",
      "(1, 'Bill_Simon')\n",
      "(2, 'Hu_Jintao')\n",
      "(3, 'Mohammed_Al-Douri')\n",
      "(4, 'Gerhard_Schroeder')\n",
      "(5, 'Kim_Ryong-sung')\n",
      "(6, 'John_Negroponte')\n",
      "(7, 'Juan_Carlos_Ferrero')\n",
      "(8, 'Richard_Myers')\n",
      "(9, 'Hillary_Clinton')\n",
      "(10, 'Angelina_Jolie')\n",
      "(11, 'Tim_Henman')\n",
      "(12, 'Mark_Philippoussis')\n",
      "(13, 'Arnold_Schwarzenegger')\n",
      "(14, 'Spencer_Abraham')\n",
      "(15, 'Mike_Weir')\n",
      "(16, 'Wen_Jiabao')\n",
      "(17, 'Kim_Clijsters')\n",
      "(18, 'Walter_Mondale')\n",
      "(19, 'Rubens_Barrichello')\n",
      "(20, 'John_Ashcroft')\n",
      "(21, 'Gray_Davis')\n",
      "(22, 'Sergey_Lavrov')\n",
      "(23, 'Anna_Kournikova')\n",
      "(24, 'Andre_Agassi')\n",
      "(25, 'John_Howard')\n",
      "(26, 'Michael_Jackson')\n",
      "(27, 'Colin_Powell')\n",
      "(28, 'Norah_Jones')\n",
      "(29, 'Vladimir_Putin')\n",
      "(30, 'Nicole_Kidman')\n",
      "(31, 'Ricardo_Lagos')\n",
      "(32, 'Jeremy_Greenstock')\n",
      "(33, 'Naji_Sabri')\n",
      "(34, 'George_Robertson')\n",
      "(35, 'Kofi_Annan')\n",
      "(36, 'John_Kerry')\n",
      "(37, 'Yasser_Arafat')\n",
      "(38, 'Lleyton_Hewitt')\n",
      "(39, 'Jeb_Bush')\n",
      "(40, 'Winona_Ryder')\n",
      "(41, 'Megawati_Sukarnoputri')\n",
      "(42, 'Charles_Moose')\n",
      "(43, 'Mahathir_Mohamad')\n",
      "(44, 'Dominique_de_Villepin')\n",
      "(45, 'Li_Zhaoxing')\n",
      "(46, 'Salma_Hayek')\n",
      "(47, 'Bill_Clinton')\n",
      "(48, 'Fidel_Castro')\n",
      "(49, 'Sergio_Vieira_De_Mello')\n",
      "(50, 'Nancy_Pelosi')\n",
      "(51, 'Igor_Ivanov')\n",
      "(52, 'Jack_Straw')\n",
      "(53, 'Tiger_Woods')\n",
      "(54, 'Lucio_Gutierrez')\n",
      "(55, 'Jennifer_Aniston')\n",
      "(56, 'Ari_Fleischer')\n",
      "(57, 'Bill_Gates')\n",
      "(58, 'Donald_Rumsfeld')\n",
      "(59, 'Mahmoud_Abbas')\n",
      "(60, 'Julie_Gerberding')\n",
      "(61, 'Silvio_Berlusconi')\n",
      "(62, 'Junichiro_Koizumi')\n",
      "(63, 'Trent_Lott')\n",
      "(64, 'Ann_Veneman')\n",
      "(65, 'Tommy_Franks')\n",
      "(66, 'Dick_Cheney')\n",
      "(67, 'Alvaro_Uribe')\n",
      "(68, 'Hugh_Grant')\n",
      "(69, 'David_Nalbandian')\n",
      "(70, 'Julianne_Moore')\n",
      "(71, 'John_Snow')\n",
      "(72, 'Eduardo_Duhalde')\n",
      "(73, 'Jean-David_Levitte')\n",
      "(74, 'Richard_Gephardt')\n",
      "(75, 'Abdullah_Gul')\n",
      "(76, 'Roger_Federer')\n",
      "(77, 'Adrien_Brody')\n",
      "(78, 'Venus_Williams')\n",
      "(79, 'Charles_Taylor')\n",
      "(80, 'Tom_Daschle')\n",
      "(81, 'Gordon_Brown')\n",
      "(82, 'Lindsay_Davenport')\n",
      "(83, 'Luiz_Inacio_Lula_da_Silva')\n",
      "(84, 'Pierce_Brosnan')\n",
      "(85, 'Atal_Bihari_Vajpayee')\n",
      "(86, 'George_W_Bush')\n",
      "(87, 'Laura_Bush')\n",
      "(88, 'Nicanor_Duarte_Frutos')\n",
      "(89, 'Paul_Burrell')\n",
      "(90, 'Meryl_Streep')\n",
      "(91, 'Guillermo_Coria')\n",
      "(92, 'Alejandro_Toledo')\n",
      "(93, 'Jose_Maria_Aznar')\n",
      "(94, 'Vicente_Fox')\n",
      "(95, 'David_Beckham')\n",
      "(96, 'Lance_Armstrong')\n",
      "(97, 'Jennifer_Garner')\n",
      "(98, 'Catherine_Zeta-Jones')\n",
      "(99, 'Ariel_Sharon')\n",
      "(100, 'Carlos_Moya')\n",
      "(101, 'Saddam_Hussein')\n",
      "(102, 'Condoleezza_Rice')\n",
      "(103, 'Harrison_Ford')\n",
      "(104, 'Joe_Lieberman')\n",
      "(105, 'Jacques_Chirac')\n",
      "(106, 'Andy_Roddick')\n",
      "(107, 'Tang_Jiaxuan')\n",
      "(108, 'Pervez_Musharraf')\n",
      "(109, 'Renee_Zellweger')\n",
      "(110, 'Pete_Sampras')\n",
      "(111, 'Jean_Chretien')\n",
      "(112, 'Halle_Berry')\n",
      "(113, 'Tom_Ridge')\n",
      "(114, 'Tony_Blair')\n",
      "(115, 'Hans_Blix')\n",
      "(116, 'John_Paul_II')\n",
      "(117, 'Britney_Spears')\n",
      "(118, 'Serena_Williams')\n",
      "(119, 'Recep_Tayyip_Erdogan')\n",
      "(120, 'Hamid_Karzai')\n",
      "(121, 'Keanu_Reeves')\n",
      "(122, 'Gonzalo_Sanchez_de_Lozada')\n",
      "(123, 'Hugo_Chavez')\n",
      "(124, 'James_Kelly')\n",
      "(125, 'Carlos_Menem')\n",
      "(126, 'Michael_Bloomberg')\n",
      "(127, 'Paul_Bremer')\n",
      "(128, 'Jennifer_Lopez')\n",
      "(129, 'John_Allen_Muhammad')\n",
      "(130, 'Jennifer_Capriati')\n",
      "(131, 'John_Bolton')\n",
      "(132, 'Amelie_Mauresmo')\n",
      "(133, 'Taha_Yassin_Ramadan')\n",
      "(134, 'Roh_Moo-hyun')\n",
      "(135, 'Jiri_Novak')\n",
      "(136, 'Nestor_Kirchner')\n",
      "(137, 'Jiang_Zemin')\n",
      "(138, 'Jackie_Chan')\n",
      "(139, 'Joschka_Fischer')\n",
      "(140, 'Jesse_Jackson')\n",
      "(141, 'Michael_Schumacher')\n",
      "(142, 'George_HW_Bush')\n",
      "(143, 'Jason_Kidd')\n",
      "(144, 'Gloria_Macapagal_Arroyo')\n",
      "(145, 'Naomi_Watts')\n",
      "(146, 'Howard_Dean')\n",
      "(147, 'Bill_McBride')\n",
      "(148, 'Yoriko_Kawaguchi')\n",
      "(149, 'Colin_Farrell')\n",
      "(150, 'Jean_Charest')\n",
      "(151, 'Mohammad_Khatami')\n",
      "(152, 'Edmund_Stoiber')\n",
      "(153, 'Queen_Elizabeth_II')\n",
      "(154, 'Rudolph_Giuliani')\n"
     ]
    }
   ],
   "source": [
    "len(selected)\n",
    "print('\\n'.join(map(str, to_names.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.800649350649\n",
      "0.721343873518\n",
      "0.774467159635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "param_grid = [\n",
    "    {'C': [1, 10, 100, 1000],\n",
    "     'kernel': ['linear']},\n",
    "    {'C': [1, 10, 100, 1000],\n",
    "     'gamma': [0.001, 0.0001],\n",
    "     'kernel': ['rbf']}\n",
    "]\n",
    "\n",
    "clf = SVC(C=1, kernel='linear', probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(accuracy_score(y_train, clf.predict(X_train)))\n",
    "print(accuracy_score(y_test, clf.predict(X_test)))\n",
    "print(accuracy_score(ys, clf.predict(Xs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze(frame):\n",
    "    print(frame.shape)\n",
    "    faces = get_faces_from_img(frame)\n",
    "    if not faces:\n",
    "        return [], []\n",
    "    print(len(shape))\n",
    "    print(faces[0].shape)\n",
    "    es = get_embeddings([prewhiten(f) for f in faces])\n",
    "    pobas = [clf.predict_proba(e) for e in es]\n",
    "    ys = [np.argmax(prob) for prob in probas]\n",
    "    ps = [prob[y] for prob, y in zip(probas, ys)]\n",
    "    \n",
    "    return faces, ys, ps\n",
    "    \n",
    "        \n",
    "\n",
    "def capture_frame():  \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        cv2.imshow('frame', frame)\n",
    "    cap.release()\n",
    "    return frame\n",
    "\n",
    "def to_rgb(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bdf1b78ddcbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-c28cecf28e23>\u001b[0m in \u001b[0;36mcapture_frame\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frame = capture_frame()\n",
    "faces, ys, ps = analyze(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
